This video examines the features of Watson
Studio that helps to ensure fairness and explainability of machine learning pipelines, as well as
monitor their performance after deployment. IBM Watson OpenScale is a product that includes
several important features. It can test the model and its predictions
for fairness and apply ways to overcome bias. It can also help to provide explanations for
model predictions that are often hard to get but are necessary for compliance in some application
areas. It monitors the model performance and can
detect its deterioration, or "model drift," over time. It can alert the users when drift is detected
and explain which predictors are causing it. We can specify criteria under which the model
gets automatically retrained on fresh data. It also helps to measure how the model helps
the business. The attributes to monitor for bias are automatically
recommended based on prior experience. They can be edited as needed. OpenScale then keeps track of model predictions
for the specified groups and checks for bias in the predictions. Users need to know that their AI models are
fair, but the data their models were trained on can include unwanted biases which may unintentionally
be included in the resulting models. IBM Watson OpenScale can detect bias when
a model is in production and not just when it's being built. In this demo of Watson OpenScale, we'll monitor
the Credit Risk model which has been trained to determine whether or not someone is eligible
for a loan based on a variety of different features such as their credit history, age,
and their number of dependents. After launching OpenScale we can see a metrics
for the monitored model such as its quality and a fairness score. What OpenScale does is measure a model's fairness
by calculating the difference between the rates at which different groups, for example,
women versus men, receive the same outcome. A fairness value below 100% means that the
monitored group receives an unfavorable outcome more often than the reference group. In this case, we see that women are receiving
a "no risk" outcome or getting approved for loans at a lower rate than men. OpenScale enables the inspection of each model's
training data and this reveals that there was more training data for men than women. This can give some insight as to why the model
exhibits bias against women who apply for loans. Data scientists can use this information to
improve the model. Now detecting bias is one thing, OpenScale
can also mitigate it by creating a debiased model that runs alongside the monitored one. In this case, the debiased model is 12% more
fair than the production model. The debiased model has been trained to detect
when your production model will make a bias prediction. So that you can isolate a specific transaction
that results in a bias. For each of these transactions Watson OpenScale
will flip the monitored value in a record to the reference value, in this case from
female to male, and leave all other data points in that record the same. If this changes the prediction from risk to
no-risk, then the debiased model will surface the no-risk outcome as the debiased result. This is just one of the ways Watson OpenScale
helps you ensure that your models are fair, explainable and compliant, wherever your model
was built or is running. Insurance underwriters can use machine learning and OpenScale to
more consistently and accurately assess claims risk, ensure fair outcomes for customers and
explain AI recommendations for regulatory and business intelligence purposes. Why does an AI model arrive at a given recommendation
or prediction? Users and customers want an explanation and
with most models providing this information is not an easy task. IBM Watson OpenScale explains predictions
in business-friendly language. This credit application for instance was predicted
to be at risk. OpenScale determines the features which contributed
positively or negatively to that prediction and spells them out. The explanation is presented visually, as
well as in a sentence based text summary in order to ensure maximum clarity. Using proprietary IBM research technology,
OpenScale also generates a contrast of explanation. Here we see the minimum changes for this input
record which would produce a different output, changing the prediction from risk to no-risk. The explanations provided by Watson OpenScale
can help organizations comply with regulations such as the Fair Credit Reporting Act and
GDPR, which give customers the right to ask for reasons why their applications were denied. Before an AI model is put into production,
it must prove it can make accurate predictions on test data, a subset of its training data,
however, over time production data can begin to look different than training data, causing
the model to start making less accurate predictions. This is called drift. IBM Watson OpenScale monitors a model's accuracy
on production data and compares it to accuracy on its training data. When a difference in accuracy exceeds a chosen
threshold, OpenScale generates an alert. Watson OpenScale reveals which transactions
caused drift and identifies the top transaction 76
00:05:58,590 --> 00:06:04,250
For instance, 25% of the transactions causing
drift in this loan approval model were problematic because of these features, which contain data
crucially different than the training data. The transactions causing drift can be sent
from manual labeling and used to retrain the model so that its predictive accuracy does
not drop at run time. Watson OpenScale not only helps identify drift
but also highlights its root cause and provides transactions which can be turned into training
data useful in fixing drift. It gives you the insight you need to ensure
that your models will consistently deliver the results you want over time. For instance, the retrain version of the model
based on the recommendations made by Watson OpenScale, started making accurate recommendations
alleviating the drift. This is just one of the ways that Watson OpenScale
helps you ensure your models are fair, explainable and compliant wherever your model was built
or is running. In this video, you have learned how OpenScale
ensures fairness and explainability of models and monitors for model drift in production. This completes the module on IBM products
for data scientists. Good luck on the quizzes!